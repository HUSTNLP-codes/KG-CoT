{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1541/1541 [00:00<00:00, 12427.56it/s]\n"
     ]
    }
   ],
   "source": [
    "input_json_list = list()\n",
    "with open(\"webqsp_hit30.json\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in tqdm(lines):\n",
    "        line = line.strip()\n",
    "        json_line = json.loads(line)\n",
    "        input_json_list.append(json_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1541/1541 [00:00<00:00, 62573.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_question_list = list()\n",
    "for piece_json in tqdm(input_json_list):\n",
    "    all_paths = \"\"\n",
    "    for elem in piece_json['top10_path']:\n",
    "        if piece_json['top10_path'][elem][0]['priority'] < 30: \n",
    "        # print(piece_json['top10_path'][elem][0]['path'])\n",
    "            all_paths += \"{Path: \" +  piece_json['top10_path'][elem][0]['path'] + \"}\\n\"\n",
    "    new_question_piece = {\n",
    "        'Question': piece_json['question'] + '\\n',\n",
    "        'Relational Facts': all_paths,\n",
    "        'Answer List': piece_json['answer'],\n",
    "    }\n",
    "    new_question_list.append(new_question_piece)\n",
    "# print(new_question_piece)\n",
    "print(len(new_question_list))\n",
    "# print(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what did james k polk do before he was president\n",
      "{Path: James K. Polk --> government.politician.government_positions_held --> m.04j5sk8 --> government.government_position_held.office_position_or_title --> Governor of Tennessee}\n",
      "{Path: James K. Polk --> government.politician.government_positions_held --> m.04j60kc --> government.government_office_or_title.office_holders_reverse --> United States Representative}\n",
      "{Path: James K. Polk --> government.politician.government_positions_held --> m.0944j8_ --> government.government_office_or_title.office_holders_reverse --> Speaker of the United States House of Representatives}\n",
      "{Path: James K. Polk --> government.government_position_held.office_holder_reverse --> m.04469y8 --> government.government_office_or_title.office_holders_reverse --> President dels Estats Units}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_question = new_question_list[1]\n",
    "answer_list = input_question['Answer List']\n",
    "question_piece = input_question['Question'] + input_question['Relational Facts']\n",
    "print(question_piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1541 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1541/1541 [37:16<00:00,  1.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8494484101232965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "count = 0\n",
    "correct = 0\n",
    "output_list = list()\n",
    "i = 0\n",
    "j = 0\n",
    "for input_question in tqdm(new_question_list):\n",
    "    answer_list = input_question['Answer List']\n",
    "    question_piece = question_piece = input_question['Question'] + input_question['Relational Facts']\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"your API key\"  \n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-0125\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"{question_piece}\" + '\\n'\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\"\"Based on the relational facts provided, you are asked to return all answer entities directly.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0,\n",
    "    }\n",
    "\n",
    "    try_again = 0\n",
    "    while try_again < 5:\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", json=data, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "        try_again += 1\n",
    "    if try_again == 5:\n",
    "        print(\"api call failed!\")\n",
    "        continue\n",
    "\n",
    "    prediction = response.json()['choices'][0]['message']['content']\n",
    "\n",
    "    is_correct = False\n",
    "    filtered_prediction = re.sub(r'[^a-zA-Z0-9\\s]', '', prediction)\n",
    "    for answer in answer_list:\n",
    "        if '(' in answer and ')' in answer:\n",
    "            answer = answer[:answer.index('(')]\n",
    "        filtered_answer = re.sub(r'[^a-zA-Z0-9\\s]', '', answer)\n",
    "        if filtered_answer.lower() in filtered_prediction.lower():\n",
    "            is_correct = True\n",
    "            correct += 1\n",
    "            break\n",
    "        elif filtered_prediction.lower() in filtered_answer.lower():\n",
    "            is_correct = True\n",
    "            correct += 1\n",
    "            break\n",
    "        elif '{' in prediction and '}' in prediction:\n",
    "            entity = re.sub(r'[^a-zA-Z0-9\\s]', '', prediction[prediction.index('{')+1:prediction.index('}')])\n",
    "            if entity.lower() in filtered_answer.lower() or filtered_answer.lower() in entity.lower():\n",
    "                is_correct = True\n",
    "                correct += 1\n",
    "                break\n",
    "        else:\n",
    "            is_correct = False\n",
    "    count += 1\n",
    "\n",
    "    output_data = {}\n",
    "    output_data['question'] = question_piece\n",
    "    output_data['prediction'] = prediction\n",
    "    output_data['answer_list'] = answer_list\n",
    "    output_data['is_correct'] = is_correct\n",
    "    output_data = json.dumps(output_data)\n",
    "    output_list.append(output_data)\n",
    "\n",
    "file = open('result.txt', 'w')\n",
    "for elem in output_list:\n",
    "    file.write(elem)\n",
    "    file.write('\\n')\n",
    "file.close()\n",
    "print(correct/count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
